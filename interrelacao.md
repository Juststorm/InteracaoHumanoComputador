# A Inter-relação entre algoritmos racistas e a explicabilidade de sistemas interativos

_Esta composição textual é elaborada a partir de uma análise e relação entre dois artigos de pesquisa: “Algoritmos racistas: a hiper-ritualização da solidão da mulher negra em bancos de imagens digitais”, de Fernanda Carrera e Denise Carvalho, e “Exploring User Profiles Based on their Explainability Requirements in Interactive Systems” ou “Explorando Perfis de Usuário Baseado em seus Requisitos de Explicabilidade em Sistemas Interativos”, de Henrique Louzada, Gabriel Chaves e Lesandro Ponciano. 
O alicerce deste texto são questionamentos._

O primeiro texto trata de algoritmo racistas, a forma como sistemas computacionais, no caso da análise, banco de imagens, tratam a figura humana e retornam resultados de acordo com palavras-chave. O segundo texto trata da necessidade de explicabilidade pelos usuários dos sistemas de informação – como os dados recebidos são processados e geram determinada saída -, como isso impacta no cotidiano, nas decisões, e qual seu significado. 
Podemos relacionar de forma explícita e levantar, de cara, um questionamento: os ditos algoritmos racistas demandam explicação ou eles são autoexplicativos? O que isso quer dizer? Bom, será que por causa do conhecimento de mundo que já fundamos e da evolução do pensamento humano para responder certas questões automaticamente e dos mais diversos absurdos que enfrentamos rotineiramente, será que uma explicação para esse terrível problema já não tem resposta? 
De outra forma, será que por conta da não transparência e explicabilidade desses bancos de imagem para fundar seus resultados de busca, será que não podemos fazer outra pergunta: o comodismo/conformidade ao se deparar com resultado de buscas por algumas pessoas demonstra que elas são uma extensão do algoritmo racista ou que elas se colocam numa posição de ‘ninguém fez nada, eu que não vou fazer’? Essa pergunta traz duas alternativas diretas, mas é possível obter alguns desdobramentos. A explicação para ela é simples, a resposta, nem tanto – se as pessoas estão “felizes” ao obterem os resultados exibidos pelos algoritmos racistas e estão dispostas a usarem aquele conteúdo em seus trabalhos sem pestanejar, não significaria que elas são racistas ou produto do racismo? Ou, quem sabe, porque as massas não tomam iniciativa e realizam um movimento – ou por talvez esse movimento específico não ter tanta força – essas pessoas também não tomam?
Vivemos em um mundo muito diferente do de 50 anos atrás – ou, ainda, do que o de 100 anos atrás -, então podemos fundar mais um questionamento baseado nos textos: o avanço da tecnologia, do ser humano, das políticas, não demandam que a explicabilidade para esse tipo de situação, além de serem um recurso moral e ético obrigatório, sejam também tecnologicamente exigidos? Isso é, quando tratamos da mentalidade do ser humano, percebemos que ela evoluiu. Barreiras culturais foram quebradas. Preconceitos e estereótipos, muitos, desmitificados consensualmente pelos mais sãos. Esta pergunta traz para o debate o seguinte: já que houve esse avanço, não deveria ser natural para todos que os resultados trazidos por esses algoritmos que podem ser polêmicos sejam explicados? Para o seu bem e do outro.  Ainda, trazendo como exemplo, no Brasil é obrigatório que lojas virtuais (e-commerces) exponham seu Cadastro Nacional de Pessoa Jurídica (CNPJ) e endereço no rodapé de seu site, por que também não tornamos obrigatório (tecnologicamente) que os sites expliquem como chegaram àqueles resultados, o porquê de que aquelas imagens foram exibidas etc. Temos aplicativos e sites que exibem o passo a passo de problemas matemáticos, por que não podemos ter, da mesma forma, sites que exibem o passo a passo de seus algoritmos?
Por fim, trago mais um questionamento relacionado diretamente a um dizer filosófico: Rousseau já dizia que o ser humano é bom por natureza e a sociedade o corrompe. Seria o código do programador bom por natureza e o resultado corrompido pela sociedade? Ou seria o código corrompido por natureza? Podemos entender disso é que será que as escolhas feitas pelo usuário nas primeiras vezes que aquele algoritmo foi executado corromperam sua tendência? Você sabe se aquele algoritmo já não foi projetado com objetivos perversos ou com a tendência já corrompida porque simplesmente existem outros iguais a ele?
Novamente, os questionamentos trazidos para o debate são:
* os ditos algoritmos racistas demandam explicação ou eles são autoexplicativos?
* o comodismo/conformidade ao se deparar com resultado de buscas por algumas pessoas demonstra que elas são uma extensão do algoritmo racista ou que elas se colocam numa posição de ‘ninguém fez nada, eu que não vou fazer’?
*	o avanço da tecnologia, do ser humano, das políticas, não demandam que a explicabilidade para esse tipo de situação, além de serem um recurso moral e ético obrigatório, sejam também tecnologicamente exigidos?
*	Rousseau já dizia que o ser humano é bom por natureza e a sociedade o corrompe. Seria o código do programador bom por natureza e o resultado corrompido pela sociedade? Ou seria o código corrompido por natureza?


Como conclusão, é possível dizer que qualquer tipo de resposta neste tipo de abordagem pode ser afetada pelo dito “paradoxo” tratado no segundo texto: as pessoas podem falar que agem de uma determinada forma, mas, na prática, estão agindo de outra. Neste momento, a explicabilidade pode ser item de luxo, opcional, mas, no futuro, provavelmente será obrigatória para os softwares, sistemas computacionais.
Não esqueçamos que o algoritmo/software é obra do ser humano, e o ser humano pode ser obra do perverso ou do bondoso.


_Interação Humano-Computador – Debate Estruturado I – Lucas Lemos Pinheiro_
